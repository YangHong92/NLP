{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Self-attention-implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### This code implements below GIF of self-attetntion in PyTorch and Tensorflow"
      ],
      "metadata": {
        "id": "8MOhy8Az230u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![texto alternativo](https://pic2.zhimg.com/80/v2-b900fb952a100acd7dd8cd65ebd8bd61_1440w.gif)"
      ],
      "metadata": {
        "id": "yh-fGDj72nn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ],
      "metadata": {
        "id": "QPpVxF6V2uZi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WuglkAic2XF0"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. define input"
      ],
      "metadata": {
        "id": "mKZabJha6BWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\n",
        "  [1, 0, 1, 0], # Input 1\n",
        "  [0, 2, 0, 2], # Input 2\n",
        "  [1, 1, 1, 1]  # Input 3\n",
        " ]\n",
        "\n",
        "x = torch.tensor(x, dtype=torch.float32)\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz0bxuLy2h1X",
        "outputId": "7c1dab41-16b5-4e4d-da2a-c963e691a380"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 0.],\n",
            "        [0., 2., 0., 2.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. define weight matrix for key, query, value"
      ],
      "metadata": {
        "id": "D4_iUFTN6MXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all inputs transformed to key, query, value by sharing the same weight matrix\n",
        "w_key = [\n",
        "  [0, 0, 1],\n",
        "  [1, 1, 0],\n",
        "  [0, 1, 0],\n",
        "  [1, 1, 0]\n",
        "]\n",
        "w_query = [\n",
        "  [1, 0, 1],\n",
        "  [1, 0, 0],\n",
        "  [0, 0, 1],\n",
        "  [0, 1, 1]\n",
        "]\n",
        "w_value = [\n",
        "  [0, 2, 0],\n",
        "  [0, 3, 0],\n",
        "  [1, 0, 3],\n",
        "  [1, 1, 0]\n",
        "]\n",
        "w_key = torch.tensor(w_key, dtype=torch.float32)\n",
        "w_query = torch.tensor(w_query, dtype=torch.float32)\n",
        "w_value = torch.tensor(w_value, dtype=torch.float32)\n",
        "\n",
        "print(\"Weights for key: \\n\", w_key)\n",
        "print(\"Weights for query: \\n\", w_query)\n",
        "print(\"Weights for value: \\n\", w_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwwzfQVE54Vs",
        "outputId": "a1a006c4-3f43-40a9-aaba-e88c420c016b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights for key: \n",
            " tensor([[0., 0., 1.],\n",
            "        [1., 1., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [1., 1., 0.]])\n",
            "Weights for query: \n",
            " tensor([[1., 0., 1.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 1., 1.]])\n",
            "Weights for value: \n",
            " tensor([[0., 2., 0.],\n",
            "        [0., 3., 0.],\n",
            "        [1., 0., 3.],\n",
            "        [1., 1., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. project inputs onto weight matrix to get respective key, query, value"
      ],
      "metadata": {
        "id": "N-FEq5iH6b7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = x @ w_key\n",
        "querys = x @ w_query\n",
        "values = x @ w_value\n",
        "\n",
        "print(\"Keys: \\n\", keys)\n",
        "# tensor([[0., 1., 1.], # key for Input 1\n",
        "#         [4., 4., 0.], # key for Input 2\n",
        "#         [2., 3., 1.]]) # key for Input 3\n",
        "print(\"Querys: \\n\", querys)\n",
        "# tensor([[1., 0., 2.],  # query for Input 1\n",
        "#         [2., 2., 2.],  # query for Input 2\n",
        "#         [2., 1., 3.]]) # query for Input 3\n",
        "print(\"Values: \\n\", values)\n",
        "# tensor([[1., 2., 3.],  # value for Input 1\n",
        "#         [2., 8., 0.],  # value for Input 2\n",
        "#         [2., 6., 3.]]) # value for Input 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqKkbxYw6YU6",
        "outputId": "047f8d71-ba70-49cc-89c8-ef837020bc19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: \n",
            " tensor([[0., 1., 1.],\n",
            "        [4., 4., 0.],\n",
            "        [2., 3., 1.]])\n",
            "Querys: \n",
            " tensor([[1., 0., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 1., 3.]])\n",
            "Values: \n",
            " tensor([[1., 2., 3.],\n",
            "        [2., 8., 0.],\n",
            "        [2., 6., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. for each input, calculate attention score by obtaining context similarity between its own query and all keys (including its own key)"
      ],
      "metadata": {
        "id": "LIF_mmDg9aEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = querys @ keys.T\n",
        "\n",
        "print(attn_scores)\n",
        "# tensor([[ 2.,  4.,  4.],  # attention scores from Query 1\n",
        "#         [ 4., 16., 12.],  # attention scores from Query 2\n",
        "#         [ 4., 12., 10.]]) # attention scores from Query 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWdRKqPK8udt",
        "outputId": "34aa7534-0db4-485b-8a78-c6d8e138d5ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.,  4.,  4.],\n",
            "        [ 4., 16., 12.],\n",
            "        [ 4., 12., 10.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. apply softmax on attention score to normalize the weight"
      ],
      "metadata": {
        "id": "j3Nt8i79ArIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import softmax\n",
        "\n",
        "attn_scores_softmax= softmax(attn_scores, dim=-1)\n",
        "print(attn_scores_softmax)\n",
        "# tensor([[6.3379e-02, 4.6831e-01, 4.6831e-01],\n",
        "#         [6.0337e-06, 9.8201e-01, 1.7986e-02],\n",
        "#         [2.9539e-04, 8.8054e-01, 1.1917e-01]])\n",
        "\n",
        "# For readability, approximate the above as follows\n",
        "attn_scores_softmax = [\n",
        "  [0.0, 0.5, 0.5], # attention scores from Query 1\n",
        "  [0.0, 1.0, 0.0], # attention scores from Query 2\n",
        "  [0.0, 0.9, 0.1]  # attention scores from Query 3\n",
        "]\n",
        "attn_scores_softmax = torch.tensor(attn_scores_softmax)\n",
        "print(attn_scores_softmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVUx1YmtAqgi",
        "outputId": "64f3108f-10b5-4358-ea0f-164b6eafb0c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6.3379e-02, 4.6831e-01, 4.6831e-01],\n",
            "        [6.0337e-06, 9.8201e-01, 1.7986e-02],\n",
            "        [2.9539e-04, 8.8054e-01, 1.1917e-01]])\n",
            "tensor([[0.0000, 0.5000, 0.5000],\n",
            "        [0.0000, 1.0000, 0.0000],\n",
            "        [0.0000, 0.9000, 0.1000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. for each input, calculate its contextualised embedding from weighted values"
      ],
      "metadata": {
        "id": "bN-imtbBBTPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = attn_scores_softmax @ values \n",
        "print(outputs)\n",
        "# tensor([[2.0000, 7.0000, 1.5000],  # Output 1\n",
        "#         [2.0000, 8.0000, 0.0000],  # Output 2\n",
        "#         [2.0000, 7.8000, 0.3000]]) # Output 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVIkqlf7BJ8n",
        "outputId": "99d19e10-8663-469d-8ddf-c695ef5ad623"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.0000, 7.0000, 1.5000],\n",
            "        [2.0000, 8.0000, 0.0000],\n",
            "        [2.0000, 7.8000, 0.3000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow"
      ],
      "metadata": {
        "id": "os71K34b3U0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "VlWlfGBm3UMt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\n",
        "  [1, 0, 1, 0], # Input 1\n",
        "  [0, 2, 0, 2], # Input 2\n",
        "  [1, 1, 1, 1]  # Input 3\n",
        " ]\n",
        "\n",
        "x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKVVw9iYwVND",
        "outputId": "f605b15c-aa76-4fb0-f9a7-27f6bade8da6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0. 1. 0.]\n",
            " [0. 2. 0. 2.]\n",
            " [1. 1. 1. 1.]], shape=(3, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all inputs transformed to key, query, value by sharing the same weight matrix\n",
        "w_key = [\n",
        "  [0, 0, 1],\n",
        "  [1, 1, 0],\n",
        "  [0, 1, 0],\n",
        "  [1, 1, 0]\n",
        "]\n",
        "w_query = [\n",
        "  [1, 0, 1],\n",
        "  [1, 0, 0],\n",
        "  [0, 0, 1],\n",
        "  [0, 1, 1]\n",
        "]\n",
        "w_value = [\n",
        "  [0, 2, 0],\n",
        "  [0, 3, 0],\n",
        "  [1, 0, 3],\n",
        "  [1, 1, 0]\n",
        "]\n",
        "w_key = tf.convert_to_tensor(w_key, dtype=tf.float32)\n",
        "w_query = tf.convert_to_tensor(w_query, dtype=tf.float32)\n",
        "w_value = tf.convert_to_tensor(w_value, dtype=tf.float32)\n",
        "\n",
        "print(\"Weights for key: \\n\", w_key)\n",
        "print(\"Weights for query: \\n\", w_query)\n",
        "print(\"Weights for value: \\n\", w_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al_eye3bwfAo",
        "outputId": "e7bf99a5-8175-49f1-d2c5-e987873d88ee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights for key: \n",
            " tf.Tensor(\n",
            "[[0. 0. 1.]\n",
            " [1. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 1. 0.]], shape=(4, 3), dtype=float32)\n",
            "Weights for query: \n",
            " tf.Tensor(\n",
            "[[1. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 1.]], shape=(4, 3), dtype=float32)\n",
            "Weights for value: \n",
            " tf.Tensor(\n",
            "[[0. 2. 0.]\n",
            " [0. 3. 0.]\n",
            " [1. 0. 3.]\n",
            " [1. 1. 0.]], shape=(4, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = tf.matmul(querys, keys.T)\n",
        "\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoOAf1awwwtA",
        "outputId": "ea4f1f45-0535-40e1-91ac-31e54ac60b9f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 2.  4.  4.]\n",
            " [ 4. 16. 12.]\n",
            " [ 4. 12. 10.]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_softmax = tf.nn.softmax(attn_scores, axis=-1)\n",
        "print(attn_scores_softmax)\n",
        "\n",
        "# For readability, approximate the above as follows\n",
        "attn_scores_softmax = [\n",
        "  [0.0, 0.5, 0.5], # attention scores from Query 1\n",
        "  [0.0, 1.0, 0.0], # attention scores from Query 2\n",
        "  [0.0, 0.9, 0.1]  # attention scores from Query 3\n",
        "]\n",
        "attn_scores_softmax = tf.convert_to_tensor(attn_scores_softmax)\n",
        "print(attn_scores_softmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOQ0tbCpw8Dv",
        "outputId": "736a53b3-bfc9-4a38-e1ac-64d722a712dc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[6.3378938e-02 4.6831051e-01 4.6831051e-01]\n",
            " [6.0336647e-06 9.8200780e-01 1.7986100e-02]\n",
            " [2.9538720e-04 8.8053685e-01 1.1916770e-01]], shape=(3, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.  0.5 0.5]\n",
            " [0.  1.  0. ]\n",
            " [0.  0.9 0.1]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = tf.matmul(attn_scores_softmax, values)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qrybp4CxY0U",
        "outputId": "4f603455-211a-439d-d820-2f2829fd4928"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[2.        7.        1.5      ]\n",
            " [2.        8.        0.       ]\n",
            " [2.        7.7999997 0.3      ]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v5BAJ-1axuHL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}